{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac96a418",
   "metadata": {},
   "source": [
    "Below is 12 different baseline models run on various subsets of the features.  Once I determined which seemed to work the best, I optimized that model at the bottom."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06af6ec1",
   "metadata": {},
   "source": [
    "#### Model 1 - Bucketed Age, Compensation Grade, Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa72517",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr1 = d.clean.preprocess.copy()\n",
    "\n",
    "lr1.drop(['Age', 'Job_Level', 'Country', 'Job_Category', \n",
    "                  'Job_Group_Factorized'], axis = 1, inplace = True)\n",
    "\n",
    "lr1 = pd.get_dummies(lr1, columns = ['Gender', 'Region', 'Compensation_Grade', \n",
    "                                                            'Marital_Status', 'Location', 'Ethnicity'])\n",
    "\n",
    "X = lr1.drop('Status', axis = 1)\n",
    "y = lr1['Status']\n",
    "\n",
    "print(lr1.shape)\n",
    "lr1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0885f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "#Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=2)\n",
    "\n",
    "#Fit initial model\n",
    "lr = LogisticRegression(solver = 'sag', max_iter = 1000)\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#Make predictions and output classification report\n",
    "pred = lr.predict(X_test)\n",
    "\n",
    "print('Classification Report:\\n')\n",
    "print(classification_report(y_test, pred))\n",
    "\n",
    "cm = pd.DataFrame(confusion_matrix(y_test, pred),\n",
    "                     index = ['No Churn','Churn'],\n",
    "                     columns = ['Pred_No_Churn', 'Pred_Churn'])\n",
    "\n",
    "print('\\nConfusion Matrix:\\n')\n",
    "cm['row_tot'] = cm.apply(lambda x: x.sum(), axis = 1)\n",
    "\n",
    "cm.loc['col_tot'] = cm.apply(lambda x: x.sum(), axis = 0)\n",
    "\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00ae619",
   "metadata": {},
   "source": [
    "#### Model 2 - Age Continuous, Compensation Grade, Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57c7913",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr2 = d.clean.preprocess.copy()\n",
    "\n",
    "lr2.drop(['Age_Buckets_Factorized', 'Job_Level', 'Country', 'Job_Category', \n",
    "                  'Job_Group_Factorized'], axis = 1, inplace = True)\n",
    "\n",
    "lr2 = pd.get_dummies(lr2, columns = ['Gender', 'Region', 'Compensation_Grade', \n",
    "                                                            'Marital_Status', 'Location', 'Ethnicity'])\n",
    "\n",
    "X = lr2.drop('Status', axis = 1)\n",
    "y = lr2['Status']\n",
    "#X = lr2.drop('Years_in_Service_(Continuous_Service_Date)', axis = 1)\n",
    "#y = lr2['Years_in_Service_(Continuous_Service_Date)']\n",
    "\n",
    "print(lr2.shape)\n",
    "lr2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d60b011",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into train, and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=2)\n",
    "\n",
    "#Fit initial model\n",
    "lr = LogisticRegression(solver = 'sag', max_iter = 1000)\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#Make predictions and output classification report\n",
    "pred = lr.predict(X_test)\n",
    "\n",
    "print('Classification Report:\\n')\n",
    "print(classification_report(y_test, pred))\n",
    "\n",
    "cm = pd.DataFrame(confusion_matrix(y_test, pred),\n",
    "                     index = ['No Churn','Churn'],\n",
    "                     columns = ['Pred_No_Churn', 'Pred_Churn'])\n",
    "\n",
    "print('\\nConfusion Matrix:\\n')\n",
    "cm['row_tot'] = cm.apply(lambda x: x.sum(), axis = 1)\n",
    "\n",
    "cm.loc['col_tot'] = cm.apply(lambda x: x.sum(), axis = 0)\n",
    "\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4111ce",
   "metadata": {},
   "source": [
    "#### Model 3 - Bucketed Age, Compensation Grade, Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518d4ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr3 = d.clean.preprocess.copy()\n",
    "\n",
    "lr3.drop(['Age', 'Job_Level', 'Location', 'Job_Category', \n",
    "                  'Job_Group_Factorized'], axis = 1, inplace = True)\n",
    "\n",
    "lr3 = pd.get_dummies(lr3, columns = ['Gender', 'Region', 'Compensation_Grade', \n",
    "                                                            'Marital_Status', 'Country', 'Ethnicity'])\n",
    "\n",
    "X = lr3.drop('Status', axis = 1)\n",
    "y = lr3['Status']\n",
    "\n",
    "print(lr3.shape)\n",
    "lr3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c25de42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into train, and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=2)\n",
    "\n",
    "#Fit initial model\n",
    "lr = LogisticRegression(solver = 'sag', max_iter = 2000)\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#Make predictions and output classification report\n",
    "pred = lr.predict(X_test)\n",
    "\n",
    "print('Classification Report:\\n')\n",
    "print(classification_report(y_test, pred))\n",
    "\n",
    "cm = pd.DataFrame(confusion_matrix(y_test, pred),\n",
    "                     index = ['No Churn','Churn'],\n",
    "                     columns = ['Pred_No_Churn', 'Pred_Churn'])\n",
    "\n",
    "print('\\nConfusion Matrix:\\n')\n",
    "cm['row_tot'] = cm.apply(lambda x: x.sum(), axis = 1)\n",
    "\n",
    "cm.loc['col_tot'] = cm.apply(lambda x: x.sum(), axis = 0)\n",
    "\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7627f1",
   "metadata": {},
   "source": [
    "#### Model 4 - Bucketed Age, Job Category & Job Level, Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6d26e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr4 = d.clean.preprocess.copy()\n",
    "\n",
    "lr4.drop(['Age', 'Location', 'Compensation_Grade', \n",
    "                  'Job_Group_Factorized'], axis = 1, inplace = True)\n",
    "\n",
    "lr4 = pd.get_dummies(lr4, columns = ['Gender', 'Region', 'Job_Category',\n",
    "                                                            'Marital_Status', 'Country', 'Ethnicity'])\n",
    "\n",
    "X = lr4.drop('Status', axis = 1)\n",
    "y = lr4['Status']\n",
    "\n",
    "print(lr4.shape)\n",
    "lr4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d68f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into train, and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=2)\n",
    "\n",
    "#Fit initial model\n",
    "lr = LogisticRegression(solver = 'sag', max_iter = 2000)\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#Make predictions and output classification report\n",
    "pred = lr.predict(X_test)\n",
    "\n",
    "print('Classification Report:\\n')\n",
    "print(classification_report(y_test, pred))\n",
    "\n",
    "cm = pd.DataFrame(confusion_matrix(y_test, pred),\n",
    "                     index = ['No Churn','Churn'],\n",
    "                     columns = ['Pred_No_Churn', 'Pred_Churn'])\n",
    "\n",
    "print('\\nConfusion Matrix:\\n')\n",
    "cm['row_tot'] = cm.apply(lambda x: x.sum(), axis = 1)\n",
    "\n",
    "cm.loc['col_tot'] = cm.apply(lambda x: x.sum(), axis = 0)\n",
    "\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea6e5c5",
   "metadata": {},
   "source": [
    "#### Model 5 - Bucketed Age, Job Group & Job Level, Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736818f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr5 = d.clean.preprocess.copy()\n",
    "\n",
    "lr5.drop(['Age', 'Location', 'Compensation_Grade', \n",
    "                  'Job_Category'], axis = 1, inplace = True)\n",
    "\n",
    "lr5 = pd.get_dummies(lr5, columns = ['Gender', 'Region',\n",
    "                                                            'Marital_Status', 'Country', 'Ethnicity'])\n",
    "\n",
    "X = lr5.drop('Status', axis = 1)\n",
    "y = lr5['Status']\n",
    "\n",
    "print(lr5.shape)\n",
    "lr5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de71d577",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into train, and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=2)\n",
    "\n",
    "#Fit initial model\n",
    "lr = LogisticRegression(solver = 'sag', max_iter = 2000)\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#Make predictions and output classification report\n",
    "pred = lr.predict(X_test)\n",
    "\n",
    "print('Classification Report:\\n')\n",
    "print(classification_report(y_test, pred))\n",
    "\n",
    "cm = pd.DataFrame(confusion_matrix(y_test, pred),\n",
    "                     index = ['No Churn','Churn'],\n",
    "                     columns = ['Pred_No_Churn', 'Pred_Churn'])\n",
    "\n",
    "print('\\nConfusion Matrix:\\n')\n",
    "cm['row_tot'] = cm.apply(lambda x: x.sum(), axis = 1)\n",
    "\n",
    "cm.loc['col_tot'] = cm.apply(lambda x: x.sum(), axis = 0)\n",
    "\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce44fff",
   "metadata": {},
   "source": [
    "#### Model 6 - Bucketed Age, Job Category & Job Level, Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d8c087",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr6 = d.clean.preprocess.copy()\n",
    "\n",
    "lr6.drop(['Age', 'Country', 'Compensation_Grade', \n",
    "                  'Job_Group_Factorized'], axis = 1, inplace = True)\n",
    "\n",
    "lr6 = pd.get_dummies(lr6, columns = ['Gender', 'Region', 'Job_Category',\n",
    "                                                            'Marital_Status', 'Location', 'Ethnicity'])\n",
    "\n",
    "X = lr6.drop('Status', axis = 1)\n",
    "y = lr6['Status']\n",
    "\n",
    "print(lr6.shape)\n",
    "lr6.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6121511",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Split into train, and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=2)\n",
    "\n",
    "#Fit initial model\n",
    "lr = LogisticRegression(solver = 'sag', max_iter = 2000)\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#Make predictions and output classification report\n",
    "pred = lr.predict(X_test)\n",
    "\n",
    "print('Classification Report:\\n')\n",
    "print(classification_report(y_test, pred))\n",
    "\n",
    "cm = pd.DataFrame(confusion_matrix(y_test, pred),\n",
    "                     index = ['No Churn','Churn'],\n",
    "                     columns = ['Pred_No_Churn', 'Pred_Churn'])\n",
    "\n",
    "print('\\nConfusion Matrix:\\n')\n",
    "cm['row_tot'] = cm.apply(lambda x: x.sum(), axis = 1)\n",
    "\n",
    "cm.loc['col_tot'] = cm.apply(lambda x: x.sum(), axis = 0)\n",
    "\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9e4285",
   "metadata": {},
   "source": [
    "#### Model 7 - Bucketed Age, Job Group & Job Level, Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337f43a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr7 = d.clean.preprocess.copy()\n",
    "\n",
    "lr7.drop(['Age', 'Country', 'Compensation_Grade', 'Job_Category' ], axis = 1, inplace = True)\n",
    "\n",
    "lr7 = pd.get_dummies(lr7, columns = ['Gender', 'Region',\n",
    "                                                            'Marital_Status', 'Location', 'Ethnicity'])\n",
    "\n",
    "X = lr7.drop('Status', axis = 1)\n",
    "y = lr7['Status']\n",
    "\n",
    "print(lr7.shape)\n",
    "lr7.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1570af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into train, and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=2)\n",
    "\n",
    "#Fit initial model\n",
    "lr = LogisticRegression(solver = 'sag', max_iter = 2000)\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#Make predictions and output classification report\n",
    "pred = lr.predict(X_test)\n",
    "\n",
    "print('Classification Report:\\n')\n",
    "print(classification_report(y_test, pred))\n",
    "\n",
    "cm = pd.DataFrame(confusion_matrix(y_test, pred),\n",
    "                     index = ['No Churn','Churn'],\n",
    "                     columns = ['Pred_No_Churn', 'Pred_Churn'])\n",
    "\n",
    "print('\\nConfusion Matrix:\\n')\n",
    "cm['row_tot'] = cm.apply(lambda x: x.sum(), axis = 1)\n",
    "\n",
    "cm.loc['col_tot'] = cm.apply(lambda x: x.sum(), axis = 0)\n",
    "\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce1375a",
   "metadata": {},
   "source": [
    "#### Model 8 - Continuous Age, Job Group & Job Level, Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4faac44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr8 = d.clean.preprocess.copy()\n",
    "\n",
    "lr8.drop(['Age_Buckets_Factorized', 'Country', 'Compensation_Grade', 'Job_Category' ], axis = 1, inplace = True)\n",
    "\n",
    "lr8 = pd.get_dummies(lr8, columns = ['Gender', 'Region',\n",
    "                                                            'Marital_Status', 'Location', 'Ethnicity'])\n",
    "\n",
    "X = lr8.drop('Status', axis = 1)\n",
    "y = lr8['Status']\n",
    "\n",
    "print(lr8.shape)\n",
    "lr8.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d42868",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into train, and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=2)\n",
    "\n",
    "#Fit initial model\n",
    "lr = LogisticRegression(solver = 'sag', max_iter = 2000)\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#Make predictions and output classification report\n",
    "pred = lr.predict(X_test)\n",
    "\n",
    "print('Classification Report:\\n')\n",
    "print(classification_report(y_test, pred))\n",
    "\n",
    "cm = pd.DataFrame(confusion_matrix(y_test, pred),\n",
    "                     index = ['No Churn','Churn'],\n",
    "                     columns = ['Pred_No_Churn', 'Pred_Churn'])\n",
    "\n",
    "print('\\nConfusion Matrix:\\n')\n",
    "cm['row_tot'] = cm.apply(lambda x: x.sum(), axis = 1)\n",
    "\n",
    "cm.loc['col_tot'] = cm.apply(lambda x: x.sum(), axis = 0)\n",
    "\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f61004",
   "metadata": {},
   "source": [
    "#### Model 9 - Continuous Age, Job Group & Job Level, Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24dff663",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr9 = d.clean.preprocess.copy()\n",
    "\n",
    "lr9.drop(['Age_Buckets_Factorized', 'Compensation_Grade', 'Location', 'Job_Category' ], axis = 1, inplace = True)\n",
    "\n",
    "lr9 = pd.get_dummies(lr9, columns = ['Gender', 'Region', 'Country',\n",
    "                                                            'Marital_Status', 'Ethnicity'])\n",
    "\n",
    "X = lr9.drop('Status', axis = 1)\n",
    "y = lr9['Status']\n",
    "\n",
    "print(lr9.shape)\n",
    "lr9.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bb4720",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into train, and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=2)\n",
    "\n",
    "#Fit initial model\n",
    "lr = LogisticRegression(solver = 'sag', max_iter = 2000)\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#Make predictions and output classification report\n",
    "pred = lr.predict(X_test)\n",
    "\n",
    "print('Classification Report:\\n')\n",
    "print(classification_report(y_test, pred))\n",
    "\n",
    "cm = pd.DataFrame(confusion_matrix(y_test, pred),\n",
    "                     index = ['No Churn','Churn'],\n",
    "                     columns = ['Pred_No_Churn', 'Pred_Churn'])\n",
    "\n",
    "print('\\nConfusion Matrix:\\n')\n",
    "cm['row_tot'] = cm.apply(lambda x: x.sum(), axis = 1)\n",
    "\n",
    "cm.loc['col_tot'] = cm.apply(lambda x: x.sum(), axis = 0)\n",
    "\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be2976c",
   "metadata": {},
   "source": [
    "#### Model 10 - Continuous Age, Job Category & Job Level, Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482bace5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr10 = d.clean.preprocess.copy()\n",
    "\n",
    "lr10.drop(['Age_Buckets_Factorized', 'Country', 'Compensation_Grade', 'Job_Group_Factorized'], axis = 1, inplace = True)\n",
    "\n",
    "lr10 = pd.get_dummies(lr10, columns = ['Gender', 'Region', 'Job_Category',\n",
    "                                                            'Marital_Status', 'Location', 'Ethnicity'])\n",
    "\n",
    "X = lr10.drop('Status', axis = 1)\n",
    "y = lr10['Status']\n",
    "\n",
    "print(lr10.shape)\n",
    "lr10.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4443927",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into train, and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=2)\n",
    "\n",
    "#Fit initial model\n",
    "lr = LogisticRegression(solver = 'sag', max_iter = 2000)\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#Make predictions and output classification report\n",
    "pred = lr.predict(X_test)\n",
    "\n",
    "print('Classification Report:\\n')\n",
    "print(classification_report(y_test, pred))\n",
    "\n",
    "cm = pd.DataFrame(confusion_matrix(y_test, pred),\n",
    "                     index = ['No Churn','Churn'],\n",
    "                     columns = ['Pred_No_Churn', 'Pred_Churn'])\n",
    "\n",
    "print('\\nConfusion Matrix:\\n')\n",
    "cm['row_tot'] = cm.apply(lambda x: x.sum(), axis = 1)\n",
    "\n",
    "cm.loc['col_tot'] = cm.apply(lambda x: x.sum(), axis = 0)\n",
    "\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba0090f",
   "metadata": {},
   "source": [
    "#### Model 11 - Continuous Age, Job Category & Job Level, Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56faf86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr11 = d.clean.preprocess.copy()\n",
    "\n",
    "lr11.drop(['Age_Buckets_Factorized', 'Location', 'Compensation_Grade',  'Job_Group_Factorized'], axis = 1, inplace = True)\n",
    "\n",
    "lr11 = pd.get_dummies(lr11, columns = ['Gender', 'Region', 'Country', 'Job_Category',\n",
    "                                                            'Marital_Status', 'Ethnicity'])\n",
    "\n",
    "X = lr11.drop('Status', axis = 1)\n",
    "y = lr11['Status']\n",
    "\n",
    "print(lr11.shape)\n",
    "lr11.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbbb9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into train, and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=2)\n",
    "\n",
    "#Fit initial model\n",
    "lr = LogisticRegression(solver = 'sag', max_iter = 2000)\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#Make predictions and output classification report\n",
    "pred = lr.predict(X_test)\n",
    "\n",
    "print('Classification Report:\\n')\n",
    "print(classification_report(y_test, pred))\n",
    "\n",
    "cm = pd.DataFrame(confusion_matrix(y_test, pred),\n",
    "                     index = ['No Churn','Churn'],\n",
    "                     columns = ['Pred_No_Churn', 'Pred_Churn'])\n",
    "\n",
    "print('\\nConfusion Matrix:\\n')\n",
    "cm['row_tot'] = cm.apply(lambda x: x.sum(), axis = 1)\n",
    "\n",
    "cm.loc['col_tot'] = cm.apply(lambda x: x.sum(), axis = 0)\n",
    "\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1686e117",
   "metadata": {},
   "source": [
    "#### Model 12 - Continuous Age, Compensation Grade, Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2b4525",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr12 = d.clean.preprocess.copy()\n",
    "\n",
    "lr12.drop(['Age_Buckets_Factorized', 'Location', 'Job_Category', \n",
    "                   'Job_Group_Factorized', 'Job_Level' ], axis = 1, inplace = True)\n",
    "\n",
    "lr12 = pd.get_dummies(lr12, columns = ['Gender', 'Region', 'Compensation_Grade',\n",
    "                                                            'Marital_Status', 'Country', 'Ethnicity'])\n",
    "\n",
    "X = lr12.drop('Status', axis = 1)\n",
    "y = lr12['Status']\n",
    "\n",
    "print(lr12.shape)\n",
    "lr12.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cbbb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into train, and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=2)\n",
    "\n",
    "#Fit initial model\n",
    "lr = LogisticRegression(solver = 'sag', max_iter = 2000)\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#Make predictions and output classification report\n",
    "pred = lr.predict(X_test)\n",
    "\n",
    "print('Classification Report:\\n')\n",
    "print(classification_report(y_test, pred))\n",
    "\n",
    "cm = pd.DataFrame(confusion_matrix(y_test, pred),\n",
    "                     index = ['No Churn','Churn'],\n",
    "                     columns = ['Pred_No_Churn', 'Pred_Churn'])\n",
    "\n",
    "print('\\nConfusion Matrix:\\n')\n",
    "cm['row_tot'] = cm.apply(lambda x: x.sum(), axis = 1)\n",
    "\n",
    "cm.loc['col_tot'] = cm.apply(lambda x: x.sum(), axis = 0)\n",
    "\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e9f2fe",
   "metadata": {},
   "source": [
    "#### Model 2 Improvement\n",
    "\n",
    "Model 2 had the best performance, so I will try to optimize that model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5cc136",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recall the model 2 dataset\n",
    "\n",
    "X = lr2.drop('Status', axis = 1)\n",
    "y = lr2['Status']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171fdfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Re run model\n",
    "\n",
    "lr = LogisticRegression(max_iter = 2000)\n",
    "\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46482d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Employ Grid Search to maximize recall\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "c_vals = [100, 10, 1.0, 0.1, 0.01, 0.001]\n",
    "penalties = ['l2']\n",
    "solvers = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "\n",
    "grid = dict(solver = solvers, penalty = penalties, C = c_vals)\n",
    "\n",
    "gs = GridSearchCV(estimator=lr, \n",
    "                  param_grid=grid, \n",
    "                  scoring='recall', \n",
    "                  cv=10,\n",
    "                  n_jobs=-1)\n",
    "gs = gs.fit(X_train, y_train)\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b18eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Employ Grid Search to maximize accuracy\n",
    "\n",
    "c_vals = [100, 10, 1.0, 0.1, 0.01, 0.001]\n",
    "penalties = ['l2']\n",
    "solvers = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "\n",
    "grid = dict(solver = solvers, penalty = penalties, C = c_vals)\n",
    "\n",
    "gs = GridSearchCV(estimator=lr, \n",
    "                  param_grid=grid, \n",
    "                  scoring='accuracy', \n",
    "                  cv=10,\n",
    "                  n_jobs=-1)\n",
    "gs = gs.fit(X_train, y_train)\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd85d92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Re-run model with parameters for recall\n",
    "\n",
    "lr = LogisticRegression(max_iter = 2000, C = 100, penalty = 'l2', solver = 'lbfgs')\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "pred = lr.predict(X_test)\n",
    "\n",
    "print('Classification Report:\\n')\n",
    "print(classification_report(y_test, pred))\n",
    "\n",
    "cm = pd.DataFrame(confusion_matrix(y_test, pred),\n",
    "                     index = ['No Churn','Churn'],\n",
    "                     columns = ['Pred_No_Churn', 'Pred_Churn'])\n",
    "\n",
    "print('\\nConfusion Matrix:\\n')\n",
    "cm['row_tot'] = cm.apply(lambda x: x.sum(), axis = 1)\n",
    "\n",
    "cm.loc['col_tot'] = cm.apply(lambda x: x.sum(), axis = 0)\n",
    "\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16651b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Re-run model with parameters for accuracy\n",
    "\n",
    "lr = LogisticRegression(max_iter = 2000, C = .001, penalty = 'l2', solver = 'saga')\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "pred = lr.predict(X_test)\n",
    "\n",
    "print('Classification Report:\\n')\n",
    "print(classification_report(y_test, pred))\n",
    "\n",
    "cm = pd.DataFrame(confusion_matrix(y_test, pred),\n",
    "                     index = ['No Churn','Churn'],\n",
    "                     columns = ['Pred_No_Churn', 'Pred_Churn'])\n",
    "\n",
    "print('\\nConfusion Matrix:\\n')\n",
    "cm['row_tot'] = cm.apply(lambda x: x.sum(), axis = 1)\n",
    "\n",
    "cm.loc['col_tot'] = cm.apply(lambda x: x.sum(), axis = 0)\n",
    "\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad4febf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try saga with l1 penalty and different C values\n",
    "\n",
    "lr = LogisticRegression(max_iter = 2000, C = .01, penalty = 'l1', solver = 'saga')\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "pred = lr.predict(X_test)\n",
    "\n",
    "print('Classification Report:\\n')\n",
    "print(classification_report(y_test, pred))\n",
    "\n",
    "cm = pd.DataFrame(confusion_matrix(y_test, pred),\n",
    "                     index = ['No Churn','Churn'],\n",
    "                     columns = ['Pred_No_Churn', 'Pred_Churn'])\n",
    "\n",
    "print('\\nConfusion Matrix:\\n')\n",
    "cm['row_tot'] = cm.apply(lambda x: x.sum(), axis = 1)\n",
    "\n",
    "cm.loc['col_tot'] = cm.apply(lambda x: x.sum(), axis = 0)\n",
    "\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a88e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Explore using the elasticnet penalty\n",
    "\n",
    "c_vals = [100, 10, 1.0, 0.1, 0.01, 0.001]\n",
    "penalties = ['elasticnet']\n",
    "solvers = ['saga']\n",
    "ratios = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "\n",
    "grid = dict(solver = solvers, penalty = penalties, C = c_vals, l1_ratio = ratios)\n",
    "\n",
    "gs = GridSearchCV(estimator=lr, \n",
    "                  param_grid=grid, \n",
    "                  scoring='accuracy', \n",
    "                  cv=10,\n",
    "                  n_jobs=-1)\n",
    "gs = gs.fit(X_train, y_train)\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5ef440",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(max_iter = 2000, C = .001, penalty = 'elasticnet', l1_ratio = 0.4, solver = 'saga')\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "pred = lr.predict(X_test)\n",
    "\n",
    "print('Classification Report:\\n')\n",
    "print(classification_report(y_test, pred))\n",
    "\n",
    "cm = pd.DataFrame(confusion_matrix(y_test, pred),\n",
    "                     index = ['No Churn','Churn'],\n",
    "                     columns = ['Pred_No_Churn', 'Pred_Churn'])\n",
    "\n",
    "print('\\nConfusion Matrix:\\n')\n",
    "cm['row_tot'] = cm.apply(lambda x: x.sum(), axis = 1)\n",
    "\n",
    "cm.loc['col_tot'] = cm.apply(lambda x: x.sum(), axis = 0)\n",
    "\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1186cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "pipe_lr = make_pipeline(PCA(n_components = 8), LogisticRegression(max_iter = 2000, C = .001, penalty = 'elasticnet', l1_ratio = 0.4, solver = 'saga'))\n",
    "\n",
    "pipe_lr.fit(X_train, y_train)\n",
    "\n",
    "pred = pipe_lr.predict(X_test)\n",
    "\n",
    "print('Classification Report:\\n')\n",
    "print(classification_report(y_test, pred))\n",
    "\n",
    "cm = pd.DataFrame(confusion_matrix(y_test, pred),\n",
    "                     index = ['No Churn','Churn'],\n",
    "                     columns = ['Pred_No_Churn', 'Pred_Churn'])\n",
    "\n",
    "print('\\nConfusion Matrix:\\n')\n",
    "cm['row_tot'] = cm.apply(lambda x: x.sum(), axis = 1)\n",
    "\n",
    "cm.loc['col_tot'] = cm.apply(lambda x: x.sum(), axis = 0)\n",
    "\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab77288",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pipe_lr = make_pipeline(PCA(n_components = 8), LogisticRegression(max_iter = 2000, C = .01, penalty = 'l1', solver = 'saga'))\n",
    "\n",
    "pipe_lr.fit(X_train, y_train)\n",
    "\n",
    "pred = pipe_lr.predict(X_test)\n",
    "\n",
    "print('Classification Report:\\n')\n",
    "print(classification_report(y_test, pred))\n",
    "\n",
    "cm = pd.DataFrame(confusion_matrix(y_test, pred),\n",
    "                     index = ['No Churn','Churn'],\n",
    "                     columns = ['Pred_No_Churn', 'Pred_Churn'])\n",
    "\n",
    "print('\\nConfusion Matrix:\\n')\n",
    "cm['row_tot'] = cm.apply(lambda x: x.sum(), axis = 1)\n",
    "\n",
    "cm.loc['col_tot'] = cm.apply(lambda x: x.sum(), axis = 0)\n",
    "\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da137f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try using both location AND country\n",
    "\n",
    "lr13 = d.clean.preprocess.copy()\n",
    "\n",
    "lr13.drop(['Age_Buckets_Factorized','Job_Category', \n",
    "                   'Job_Group_Factorized', 'Job_Level' ], axis = 1, inplace = True)\n",
    "\n",
    "lr13 = pd.get_dummies(lr13, columns = ['Gender', 'Region', 'Location', 'Compensation_Grade',\n",
    "                                                            'Marital_Status', 'Country', 'Ethnicity'])\n",
    "\n",
    "X = lr13.drop('Status', axis = 1)\n",
    "y = lr13['Status']\n",
    "\n",
    "print(lr13.shape)\n",
    "lr13.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5557ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into train, and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=2)\n",
    "\n",
    "#Fit initial model\n",
    "lr = LogisticRegression(solver = 'sag', max_iter = 2000)\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#Make predictions and output classification report\n",
    "pred = lr.predict(X_test)\n",
    "\n",
    "print('Classification Report:\\n')\n",
    "print(classification_report(y_test, pred))\n",
    "\n",
    "cm = pd.DataFrame(confusion_matrix(y_test, pred),\n",
    "                     index = ['No Churn','Churn'],\n",
    "                     columns = ['Pred_No_Churn', 'Pred_Churn'])\n",
    "\n",
    "print('\\nConfusion Matrix:\\n')\n",
    "cm['row_tot'] = cm.apply(lambda x: x.sum(), axis = 1)\n",
    "\n",
    "cm.loc['col_tot'] = cm.apply(lambda x: x.sum(), axis = 0)\n",
    "\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18322b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_vals = [100, 10, 1.0, 0.1, 0.01, 0.001]\n",
    "penalties = ['l2']\n",
    "solvers = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "\n",
    "grid = dict(solver = solvers, penalty = penalties, C = c_vals)\n",
    "\n",
    "gs = GridSearchCV(estimator=lr, \n",
    "                  param_grid=grid, \n",
    "                  scoring='accuracy', \n",
    "                  cv=10,\n",
    "                  n_jobs=-1)\n",
    "gs = gs.fit(X_train, y_train)\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d50caf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into train, and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=2)\n",
    "\n",
    "#Fit initial model\n",
    "lr = LogisticRegression(solver = 'saga', C = 0.001, max_iter = 2000)\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#Make predictions and output classification report\n",
    "pred = lr.predict(X_test)\n",
    "\n",
    "print('Classification Report:\\n')\n",
    "print(classification_report(y_test, pred))\n",
    "\n",
    "cm = pd.DataFrame(confusion_matrix(y_test, pred),\n",
    "                     index = ['No Churn','Churn'],\n",
    "                     columns = ['Pred_No_Churn', 'Pred_Churn'])\n",
    "\n",
    "print('\\nConfusion Matrix:\\n')\n",
    "cm['row_tot'] = cm.apply(lambda x: x.sum(), axis = 1)\n",
    "\n",
    "cm.loc['col_tot'] = cm.apply(lambda x: x.sum(), axis = 0)\n",
    "\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ef3a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Play with l1 regularization again\n",
    "\n",
    "lr = LogisticRegression(solver = 'saga', penalty = 'l1', C = 0.001, max_iter = 2000)\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#Make predictions and output classification report\n",
    "pred = lr.predict(X_test)\n",
    "\n",
    "print('Classification Report:\\n')\n",
    "print(classification_report(y_test, pred))\n",
    "\n",
    "cm = pd.DataFrame(confusion_matrix(y_test, pred),\n",
    "                     index = ['No Churn','Churn'],\n",
    "                     columns = ['Pred_No_Churn', 'Pred_Churn'])\n",
    "\n",
    "print('\\nConfusion Matrix:\\n')\n",
    "cm['row_tot'] = cm.apply(lambda x: x.sum(), axis = 1)\n",
    "\n",
    "cm.loc['col_tot'] = cm.apply(lambda x: x.sum(), axis = 0)\n",
    "\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26b2d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = pd.DataFrame(data = list(lr.coef_[0]), index = X_train.columns)\n",
    "weights.columns = ['Weight']\n",
    "\n",
    "weights[weights['Weight'] != 0].sort_values(by = 'Weight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f457fb",
   "metadata": {},
   "source": [
    "#### Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa083cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize Sigmoid Function\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    a = []\n",
    "    for item in x:\n",
    "        a.append(1/(1+math.exp(-item)))\n",
    "    return a\n",
    "x = np.arange(-15., 15., 0.2)\n",
    "sig = sigmoid(x)\n",
    "plt.plot(x,sig)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17147663",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Final Model\n",
    "\n",
    "X = lr2.drop('Status', axis = 1)\n",
    "y = lr2['Status']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=2)\n",
    "\n",
    "lr_final = LogisticRegression(max_iter = 2000, C = .01, penalty = 'l1', solver = 'saga')\n",
    "\n",
    "lr_final.fit(X_train, y_train)\n",
    "\n",
    "pred_final = lr_final.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f374dc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Dataframe with features and corresponding weights\n",
    "\n",
    "weights = pd.DataFrame(data = list(lr_final.coef_[0]), index = X_train.columns)\n",
    "weights.columns = ['Weight']\n",
    "\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3b3f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights[weights['Weight'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de0f366",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AUC and ROC curve\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot\n",
    "\n",
    "lr_final_probs = lr_final.predict_proba(X_test)\n",
    "\n",
    "print(f'AUC Score: {roc_auc_score(y_test, pred_final)}')\n",
    "\n",
    "\n",
    "lr_fpr, lr_tpr, _ = roc_curve(y_test, pred_final)\n",
    "\n",
    "pyplot.plot(lr_fpr, lr_tpr, marker='.', label='ROC Curve')\n",
    "pyplot.xlabel('False Positive Rate')\n",
    "pyplot.ylabel('True Positive Rate')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ef990d",
   "metadata": {},
   "source": [
    "Finally, I attempted to split the data into different job classes and run the models separately on those."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6e4c24",
   "metadata": {},
   "source": [
    "#### Split Data Set by Job Class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe60ca1",
   "metadata": {},
   "source": [
    "##### Operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d691b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "operators = d.clean.preprocess.copy()\n",
    "\n",
    "operators = operators[operators['Job_Group_Factorized'] == 0]\n",
    "\n",
    "print(operators.shape)\n",
    "\n",
    "operators.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ac0275",
   "metadata": {},
   "outputs": [],
   "source": [
    "operators.drop(['Age_Buckets_Factorized', 'Job_Level', 'Job_Category', \n",
    "                  'Country', 'Job_Group_Factorized'], axis = 1, inplace = True)\n",
    "\n",
    "operators = pd.get_dummies(operators, columns = ['Gender', 'Region', 'Compensation_Grade', \n",
    "                                                            'Marital_Status', 'Location', 'Ethnicity'])\n",
    "\n",
    "X = operators.drop('Status', axis = 1)\n",
    "y = operators['Status']\n",
    "\n",
    "print(operators.shape)\n",
    "operators.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac7cb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=2)\n",
    "\n",
    "c_vals = [100, 10, 1.0, 0.1, 0.01, 0.001]\n",
    "penalties = ['l2']\n",
    "solvers = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "\n",
    "grid = dict(solver = solvers, penalty = penalties, C = c_vals)\n",
    "\n",
    "gs = GridSearchCV(estimator=lr, \n",
    "                  param_grid=grid, \n",
    "                  scoring='accuracy', \n",
    "                  cv=10,\n",
    "                  n_jobs=-1)\n",
    "gs = gs.fit(X_train, y_train)\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1e008c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(solver = 'lbfgs', penalty = 'l2', C = 100, max_iter = 2000)\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "pred = lr.predict(X_test)\n",
    "\n",
    "print('Classification Report:\\n')\n",
    "print(classification_report(y_test, pred))\n",
    "\n",
    "cm = pd.DataFrame(confusion_matrix(y_test, pred),\n",
    "                     index = ['No Churn','Churn'],\n",
    "                     columns = ['Pred_No_Churn', 'Pred_Churn'])\n",
    "\n",
    "print('\\nConfusion Matrix:\\n')\n",
    "cm['row_tot'] = cm.apply(lambda x: x.sum(), axis = 1)\n",
    "\n",
    "cm.loc['col_tot'] = cm.apply(lambda x: x.sum(), axis = 0)\n",
    "\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c45d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'AUC Score: {roc_auc_score(y_test, pred)}')\n",
    "\n",
    "\n",
    "lr_fpr, lr_tpr, _ = roc_curve(y_test, pred)\n",
    "\n",
    "pyplot.plot(lr_fpr, lr_tpr, marker='.', label='ROC Curve')\n",
    "pyplot.xlabel('False Positive Rate')\n",
    "pyplot.ylabel('True Positive Rate')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52450cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = pd.DataFrame(data = list(lr.coef_[0]), index = X_train.columns)\n",
    "weights.columns = ['Weight']\n",
    "\n",
    "weights[weights['Weight'] != 0].sort_values(by = 'Weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647ecb61",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(solver = 'saga', penalty = 'l1', C = 0.01, max_iter = 2000)\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "pred = lr.predict(X_test)\n",
    "\n",
    "print('Classification Report:\\n')\n",
    "print(classification_report(y_test, pred))\n",
    "\n",
    "cm = pd.DataFrame(confusion_matrix(y_test, pred),\n",
    "                     index = ['No Churn','Churn'],\n",
    "                     columns = ['Pred_No_Churn', 'Pred_Churn'])\n",
    "\n",
    "print('\\nConfusion Matrix:\\n')\n",
    "cm['row_tot'] = cm.apply(lambda x: x.sum(), axis = 1)\n",
    "\n",
    "cm.loc['col_tot'] = cm.apply(lambda x: x.sum(), axis = 0)\n",
    "\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e1ea4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = pd.DataFrame(data = list(lr.coef_[0]), index = X_train.columns)\n",
    "weights.columns = ['Weight']\n",
    "\n",
    "weights[weights['Weight'] != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9678057",
   "metadata": {},
   "source": [
    "##### Executives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8dadf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "executives = d.clean.preprocess.copy()\n",
    "\n",
    "executives = executives[executives['Job_Group_Factorized'] != 0]\n",
    "\n",
    "print(executives.shape)\n",
    "\n",
    "executives.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af0f027",
   "metadata": {},
   "outputs": [],
   "source": [
    "executives.drop(['Age_Buckets_Factorized', 'Job_Level', 'Job_Category', \n",
    "                  'Country', 'Job_Group_Factorized'], axis = 1, inplace = True)\n",
    "\n",
    "executives = pd.get_dummies(executives, columns = ['Gender', 'Region', 'Compensation_Grade', \n",
    "                                                            'Marital_Status', 'Location', 'Ethnicity'])\n",
    "\n",
    "X = executives.drop('Status', axis = 1)\n",
    "y = executives['Status']\n",
    "\n",
    "print(executives.shape)\n",
    "executives.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a355080b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.9, random_state=2)\n",
    "\n",
    "c_vals = [100, 10, 1.0, 0.1, 0.01, 0.001]\n",
    "penalties = ['l2']\n",
    "solvers = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "\n",
    "grid = dict(solver = solvers, penalty = penalties, C = c_vals)\n",
    "\n",
    "gs = GridSearchCV(estimator=lr, \n",
    "                  param_grid=grid, \n",
    "                  scoring='recall', \n",
    "                  cv=10,\n",
    "                  n_jobs=-1)\n",
    "gs = gs.fit(X_train, y_train)\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c81bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(solver = 'newton-cg', penalty = 'l2', C = 10, max_iter = 2000)\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "pred = lr.predict(X_test)\n",
    "\n",
    "print('Classification Report:\\n')\n",
    "print(classification_report(y_test, pred))\n",
    "\n",
    "cm = pd.DataFrame(confusion_matrix(y_test, pred),\n",
    "                     index = ['No Churn','Churn'],\n",
    "                     columns = ['Pred_No_Churn', 'Pred_Churn'])\n",
    "\n",
    "print('\\nConfusion Matrix:\\n')\n",
    "cm['row_tot'] = cm.apply(lambda x: x.sum(), axis = 1)\n",
    "\n",
    "cm.loc['col_tot'] = cm.apply(lambda x: x.sum(), axis = 0)\n",
    "\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38db224",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'AUC Score: {roc_auc_score(y_test, pred)}')\n",
    "\n",
    "\n",
    "lr_fpr, lr_tpr, _ = roc_curve(y_test, pred)\n",
    "\n",
    "pyplot.plot(lr_fpr, lr_tpr, marker='.', label='ROC Curve')\n",
    "pyplot.xlabel('False Positive Rate')\n",
    "pyplot.ylabel('True Positive Rate')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb17320",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weights = pd.DataFrame(data = list(lr.coef_[0]), index = X_train.columns)\n",
    "weights.columns = ['Weight']\n",
    "\n",
    "weights[weights['Weight'] != 0].sort_values(by = 'Weight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
